{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import zlib\n",
    "import lzma\n",
    "import gzip\n",
    "import bz2\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "import time\n",
    "import csv\n",
    "import zstandard as zstd\n",
    "import blosc as bl\n",
    "import pickle\n",
    "import re\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# decorator to auth for google drive -- see: https://developers.google.com/drive/api/v3/quickstart/python\n",
    "def auth_drive(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        creds = None\n",
    "        SCOPES = ['https://www.googleapis.com/auth/drive.readonly']\n",
    "        if os.path.exists('token.pickle'):\n",
    "            with open('token.pickle', 'rb') as token:\n",
    "                creds = pickle.load(token)\n",
    "        # If there are no (valid) credentials available, let the user log in\n",
    "        if not creds or not creds.valid:\n",
    "            if creds and creds.expired and creds.refresh_token:\n",
    "                creds.refresh(Request())\n",
    "            else:\n",
    "                flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                    'credentials.json', SCOPES)\n",
    "                creds = flow.run_local_server()\n",
    "            # Save the credentials for the next run\n",
    "            with open('token.pickle', 'wb') as token:\n",
    "                pickle.dump(creds, token)\n",
    "\n",
    "        service =  build('drive', 'v2', credentials=creds)\n",
    "        kwargs['service'] = service\n",
    "        return func(*args, **kwargs)\n",
    "            \n",
    "    return wrapper\n",
    "\n",
    "# generator that obtains and collates files\n",
    "@auth_drive\n",
    "def gen_links(service):\n",
    "    results = service.children().list(folderId='1mHg9cmN6GrjEQCK02c_nd-FUHODbZ4Z5').execute()\n",
    "    items = results.get('items', [])\n",
    "    for item in items:\n",
    "        print('generating item link')\n",
    "        yield item['id']\n",
    "        \n",
    "@auth_drive\n",
    "def gen_files(file_ids, service):\n",
    "    for file_id in file_ids:\n",
    "        result = service.files().get(fileId=file_id).execute()\n",
    "        if re.search('genome\\.(gz)$', result['title']):\n",
    "            request = service.files().get_media(fileId=file_id)\n",
    "            fh = io.BytesIO()\n",
    "            downloader = MediaIoBaseDownload(fh, request)\n",
    "            done = False\n",
    "            while done is False:\n",
    "                status, done = downloader.next_chunk()\n",
    "                print(\"Download %d%%.\" % int(status.progress() * 100))\n",
    "                \n",
    "            # construct object with metadata?\n",
    "            yield {'id': file_id, 'file': fh}       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decompress(genomes):\n",
    "    for genome in genomes:\n",
    "        yield {'id': genome['id'], 'file': gzip.decompress(genome['file'].getvalue())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compression transforms\n",
    "# binary file --> binary compressed file\n",
    "\n",
    "def comp_ratio(compressor):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        uncompressed_size = sys.getsizeof(args[0])\n",
    "        compressed = compressor(*args, **kwargs)\n",
    "        compressed_size = sys.getsizeof(compressed)\n",
    "        return uncompressed_size / compressed_size\n",
    "    return wrapper\n",
    "\n",
    "@comp_ratio\n",
    "def zlib_compress(f):\n",
    "    c_z = zlib.compress(f,9)\n",
    "    return c_z\n",
    "\n",
    "@comp_ratio\n",
    "def lzma_compress(f):\n",
    "    c = lzma.LZMACompressor()\n",
    "    c_l = c.compress(f)\n",
    "    c_l += c.flush()\n",
    "    return c_l\n",
    "\n",
    "@comp_ratio\n",
    "def bz2_compress(f):\n",
    "    c = bz2.BZ2Compressor()\n",
    "    c_b = c.compress(f)\n",
    "    c_b += c.flush()\n",
    "    return c_b\n",
    "\n",
    "@comp_ratio\n",
    "def zstd_compress(f):\n",
    "    c = zstd.ZstdCompressor()\n",
    "    c_zs = c.compress(f)\n",
    "    return c_zs\n",
    "\n",
    "@comp_ratio\n",
    "def bl_compress(f):\n",
    "    return bl.compress(f)\n",
    "\n",
    "compress_transforms = [zlib_compress, lzma_compress, bz2_compress, zstd_compress, bl_compress]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generator that applies list of transforms to list of files\n",
    "def apply(genomes, transforms, log='results.csv'):\n",
    "    with open(log, 'a', newline='') as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        cols = ['genome'] + [t.__name__ for t in transforms]\n",
    "        writer.writerow(cols)\n",
    "        for genome in genomes:\n",
    "            stats = []\n",
    "            for transform in transforms:\n",
    "                print('Applying {0} to {1}',transform.__name__, genome['id'])\n",
    "                stats.append(transform(genome['file'])) # transform should output some stat for us to log\n",
    "            writer.writerow([genome['id']] + stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating item link\n",
      "generating item link\n",
      "Download 54%.\n",
      "Download 100%.\n",
      "Applying {0} to {1} wrapper 1OsHimlxsGE1D3M5tNXTAbnOuq9UAmN2k\n",
      "Applying {0} to {1} wrapper 1OsHimlxsGE1D3M5tNXTAbnOuq9UAmN2k\n",
      "Applying {0} to {1} wrapper 1OsHimlxsGE1D3M5tNXTAbnOuq9UAmN2k\n",
      "Applying {0} to {1} wrapper 1OsHimlxsGE1D3M5tNXTAbnOuq9UAmN2k\n",
      "Applying {0} to {1} wrapper 1OsHimlxsGE1D3M5tNXTAbnOuq9UAmN2k\n",
      "generating item link\n",
      "Download 100%.\n",
      "Applying {0} to {1} wrapper 1s9dNf0i3kbW88HIVaeDppT7JILDgL2wo\n",
      "Applying {0} to {1} wrapper 1s9dNf0i3kbW88HIVaeDppT7JILDgL2wo\n",
      "Applying {0} to {1} wrapper 1s9dNf0i3kbW88HIVaeDppT7JILDgL2wo\n",
      "Applying {0} to {1} wrapper 1s9dNf0i3kbW88HIVaeDppT7JILDgL2wo\n",
      "Applying {0} to {1} wrapper 1s9dNf0i3kbW88HIVaeDppT7JILDgL2wo\n",
      "generating item link\n",
      "Download 100%.\n",
      "Applying {0} to {1} wrapper 1bj4eybCY3XwujjYIKilegdtbj1q2pJ_C\n",
      "Applying {0} to {1} wrapper 1bj4eybCY3XwujjYIKilegdtbj1q2pJ_C\n",
      "Applying {0} to {1} wrapper 1bj4eybCY3XwujjYIKilegdtbj1q2pJ_C\n",
      "Applying {0} to {1} wrapper 1bj4eybCY3XwujjYIKilegdtbj1q2pJ_C\n",
      "Applying {0} to {1} wrapper 1bj4eybCY3XwujjYIKilegdtbj1q2pJ_C\n",
      "generating item link\n",
      "Download 100%.\n",
      "Applying {0} to {1} wrapper 1YKRVGYUeRgxUd-F7B60Vz_dk7s57ZEhu\n",
      "Applying {0} to {1} wrapper 1YKRVGYUeRgxUd-F7B60Vz_dk7s57ZEhu\n",
      "Applying {0} to {1} wrapper 1YKRVGYUeRgxUd-F7B60Vz_dk7s57ZEhu\n",
      "Applying {0} to {1} wrapper 1YKRVGYUeRgxUd-F7B60Vz_dk7s57ZEhu\n",
      "Applying {0} to {1} wrapper 1YKRVGYUeRgxUd-F7B60Vz_dk7s57ZEhu\n",
      "generating item link\n",
      "Download 100%.\n",
      "Applying {0} to {1} wrapper 1uGIi-4pfOoiZlIsTexPhuRrK81QW69_t\n",
      "Applying {0} to {1} wrapper 1uGIi-4pfOoiZlIsTexPhuRrK81QW69_t\n",
      "Applying {0} to {1} wrapper 1uGIi-4pfOoiZlIsTexPhuRrK81QW69_t\n",
      "Applying {0} to {1} wrapper 1uGIi-4pfOoiZlIsTexPhuRrK81QW69_t\n",
      "Applying {0} to {1} wrapper 1uGIi-4pfOoiZlIsTexPhuRrK81QW69_t\n",
      "generating item link\n",
      "Download 19%.\n",
      "Download 39%.\n",
      "Download 59%.\n",
      "Download 79%.\n",
      "Download 99%.\n",
      "Download 100%.\n",
      "Applying {0} to {1} wrapper 14YFBUNfKdmrlHVz09x1vSTBFhP36BU0N\n",
      "Applying {0} to {1} wrapper 14YFBUNfKdmrlHVz09x1vSTBFhP36BU0N\n",
      "Applying {0} to {1} wrapper 14YFBUNfKdmrlHVz09x1vSTBFhP36BU0N\n",
      "Applying {0} to {1} wrapper 14YFBUNfKdmrlHVz09x1vSTBFhP36BU0N\n",
      "Applying {0} to {1} wrapper 14YFBUNfKdmrlHVz09x1vSTBFhP36BU0N\n",
      "generating item link\n",
      "Download 100%.\n",
      "Applying {0} to {1} wrapper 1f5rSSt1DS0_mm6XrH-KiCUKbi1koUdy6\n",
      "Applying {0} to {1} wrapper 1f5rSSt1DS0_mm6XrH-KiCUKbi1koUdy6\n",
      "Applying {0} to {1} wrapper 1f5rSSt1DS0_mm6XrH-KiCUKbi1koUdy6\n",
      "Applying {0} to {1} wrapper 1f5rSSt1DS0_mm6XrH-KiCUKbi1koUdy6\n",
      "Applying {0} to {1} wrapper 1f5rSSt1DS0_mm6XrH-KiCUKbi1koUdy6\n",
      "generating item link\n",
      "Download 90%.\n",
      "Download 100%.\n",
      "Applying {0} to {1} wrapper 1nfmlUw8nIaH4VcltO7onFsouI9K-WzdY\n",
      "Applying {0} to {1} wrapper 1nfmlUw8nIaH4VcltO7onFsouI9K-WzdY\n",
      "Applying {0} to {1} wrapper 1nfmlUw8nIaH4VcltO7onFsouI9K-WzdY\n",
      "Applying {0} to {1} wrapper 1nfmlUw8nIaH4VcltO7onFsouI9K-WzdY\n",
      "Applying {0} to {1} wrapper 1nfmlUw8nIaH4VcltO7onFsouI9K-WzdY\n",
      "generating item link\n",
      "Download 12%.\n",
      "Download 24%.\n",
      "Download 36%.\n",
      "Download 48%.\n",
      "Download 60%.\n",
      "Download 73%.\n",
      "Download 85%.\n",
      "Download 97%.\n",
      "Download 100%.\n",
      "Applying {0} to {1} wrapper 1A_SQ89QyeiR_uhFSIvMQWReYv3jt6MAP\n",
      "Applying {0} to {1} wrapper 1A_SQ89QyeiR_uhFSIvMQWReYv3jt6MAP\n",
      "Applying {0} to {1} wrapper 1A_SQ89QyeiR_uhFSIvMQWReYv3jt6MAP\n",
      "Applying {0} to {1} wrapper 1A_SQ89QyeiR_uhFSIvMQWReYv3jt6MAP\n",
      "Applying {0} to {1} wrapper 1A_SQ89QyeiR_uhFSIvMQWReYv3jt6MAP\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "bytesobj cannot be larger than 2147483631 bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-70e518ef81bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_links\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-d1399c68e486>\u001b[0m in \u001b[0;36mapply\u001b[0;34m(genomes, transforms, log)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Applying {0} to {1}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenome\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenome\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# should output some stat for us to log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenome\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-7770161e0db2>\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0muncompressed_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsizeof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mcompressed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mcompressed_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsizeof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompressed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0muncompressed_size\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcompressed_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-7770161e0db2>\u001b[0m in \u001b[0;36mbl_compress\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcomp_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbl_compress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mcompress_transforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mzlib_compress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlzma_compress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbz2_compress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzstd_compress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbl_compress\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/programming/genomecompression/lib/python3.7/site-packages/blosc/toplevel.py\u001b[0m in \u001b[0;36mcompress\u001b[0;34m(bytesobj, typesize, clevel, shuffle, cname)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \"\"\"\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m     \u001b[0m_check_input_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bytesobj'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytesobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m     \u001b[0m_check_typesize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypesize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0m_check_shuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/programming/genomecompression/lib/python3.7/site-packages/blosc/toplevel.py\u001b[0m in \u001b[0;36m_check_input_length\u001b[0;34m(input_name, input_len)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_len\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mblosc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAX_BUFFERSIZE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         raise ValueError(\"%s cannot be larger than %d bytes\" %\n\u001b[0;32m--> 357\u001b[0;31m                          (input_name, blosc.MAX_BUFFERSIZE))\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: bytesobj cannot be larger than 2147483631 bytes"
     ]
    }
   ],
   "source": [
    "apply(decompress(gen_files(gen_links())), compress_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genomecompression",
   "language": "python",
   "name": "genomecompression"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
