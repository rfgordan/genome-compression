{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import zlib\n",
    "import lzma\n",
    "import gzip\n",
    "import bz2\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "import time\n",
    "import csv\n",
    "import zstandard as zstd\n",
    "import blosc as bl\n",
    "import pickle\n",
    "import re\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# decorator to auth for google drive -- see: https://developers.google.com/drive/api/v3/quickstart/python\n",
    "def auth_drive(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        creds = None\n",
    "        SCOPES = ['https://www.googleapis.com/auth/drive.readonly']\n",
    "        if os.path.exists('token.pickle'):\n",
    "            with open('token.pickle', 'rb') as token:\n",
    "                creds = pickle.load(token)\n",
    "        # If there are no (valid) credentials available, let the user log in\n",
    "        if not creds or not creds.valid:\n",
    "            if creds and creds.expired and creds.refresh_token:\n",
    "                creds.refresh(Request())\n",
    "            else:\n",
    "                flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                    'credentials.json', SCOPES)\n",
    "                creds = flow.run_local_server()\n",
    "            # Save the credentials for the next run\n",
    "            with open('token.pickle', 'wb') as token:\n",
    "                pickle.dump(creds, token)\n",
    "\n",
    "        service =  build('drive', 'v2', credentials=creds)\n",
    "        kwargs['service'] = service\n",
    "        return func(*args, **kwargs)\n",
    "            \n",
    "    return wrapper\n",
    "\n",
    "# generator that obtains and collates files\n",
    "@auth_drive\n",
    "def gen_links(service):\n",
    "    results = service.children().list(folderId='1mHg9cmN6GrjEQCK02c_nd-FUHODbZ4Z5').execute()\n",
    "    items = results.get('items', [])\n",
    "    for item in items:\n",
    "        print('generating item link')\n",
    "        yield item['id']\n",
    "        \n",
    "@auth_drive\n",
    "def gen_files(file_ids, service):\n",
    "    for file_id in file_ids:\n",
    "        result = service.files().get(fileId=file_id).execute()\n",
    "        if re.search('genome\\.(gz)$', result['title']):\n",
    "            request = service.files().get_media(fileId=file_id)\n",
    "            fh = io.BytesIO()\n",
    "            downloader = MediaIoBaseDownload(fh, request)\n",
    "            done = False\n",
    "            while done is False:\n",
    "                status, done = downloader.next_chunk()\n",
    "                print(\"Download %d%%.\" % int(status.progress() * 100))\n",
    "                \n",
    "            # construct object with metadata?\n",
    "            yield {'id': file_id, 'file': fh}       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decompress(genomes):\n",
    "    for genome in genomes:\n",
    "        yield {'id': genome['id'], 'file': io.BytesIO(gzip.decompress(genome['file'].getvalue()))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compression transforms\n",
    "# binary file --> binary compressed file\n",
    "\n",
    "COMP_BUFFER_SIZE = 2000000000#2147483631\n",
    "CHUNK_SIZE = 100000000\n",
    "\n",
    "def comp_ratio(compressor):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        uncompressed_size = sys.getsizeof(args[0])\n",
    "        compressed_size = sum(sys.getsizeof(compressed) for compressed in compressor(*args, **kwargs))\n",
    "        return uncompressed_size / compressed_size\n",
    "    return wrapper\n",
    "\n",
    "@comp_ratio\n",
    "def zlib_compress(f):\n",
    "    f.seek(0)\n",
    "    c = zlib.compressobj(level=9)\n",
    "    done = False\n",
    "    while not done:\n",
    "        chunk = f.read(CHUNK_SIZE)\n",
    "        done = len(chunk) == 0\n",
    "        if done:\n",
    "            yield c.flush()\n",
    "        else:\n",
    "            yield c.compress(chunk)\n",
    "@comp_ratio\n",
    "def lzma_compress(f):\n",
    "    f.seek(0)\n",
    "    c = lzma.LZMACompressor()\n",
    "    done = False\n",
    "    while not done:\n",
    "        chunk = f.read(CHUNK_SIZE)\n",
    "        done = len(chunk) == 0\n",
    "        if done:\n",
    "            yield c.flush()\n",
    "        else:\n",
    "            yield c.compress(chunk)\n",
    "\n",
    "@comp_ratio\n",
    "def bz2_compress(f):\n",
    "    f.seek(0)\n",
    "    c = bz2.BZ2Compressor()\n",
    "    done = False\n",
    "    while not done:\n",
    "        chunk = f.read(CHUNK_SIZE)\n",
    "        done = len(chunk) == 0\n",
    "        if done:\n",
    "            yield c.flush()\n",
    "        else:\n",
    "            yield c.compress(chunk)\n",
    "\n",
    "@comp_ratio\n",
    "def zstd_compress(f):\n",
    "    f.seek(0)\n",
    "    c = zstd.ZstdCompressor()\n",
    "    done = False\n",
    "    while not done:\n",
    "        chunk = f.read(CHUNK_SIZE)\n",
    "        done = len(chunk) == 0\n",
    "        if not done:\n",
    "            yield c.compress(chunk)\n",
    "\n",
    "@comp_ratio\n",
    "def bl_compress(f):\n",
    "    f.seek(0)\n",
    "    done = False\n",
    "    while not done:\n",
    "        chunk = f.read(CHUNK_SIZE)\n",
    "        done = len(chunk) == 0\n",
    "        if not done:\n",
    "            yield bl.compress(chunk)\n",
    "\n",
    "compress_transforms = [zlib_compress, lzma_compress, bz2_compress, zstd_compress, bl_compress]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generator that applies list of transforms to list of files\n",
    "def apply(genomes, transforms, log='results2.csv'):\n",
    "    with open(log, 'a', newline='') as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        cols = ['genome'] + [t.__name__ for t in transforms]\n",
    "        writer.writerow(cols)\n",
    "        for genome in genomes:\n",
    "            stats = []\n",
    "            for transform in transforms:\n",
    "                print('Applying {0} to {1}',transform.__name__, genome['id'])\n",
    "                stats.append(transform(genome['file'])) # transform should output some stat for us to log\n",
    "            print([genome['id'] + stats])\n",
    "            writer.writerow([genome['id']] + stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating item link\n",
      "generating item link\n",
      "generating item link\n",
      "Download 54%.\n",
      "Download 100%.\n",
      "Applying {0} to {1} wrapper 1OsHimlxsGE1D3M5tNXTAbnOuq9UAmN2k\n",
      "Applying {0} to {1} wrapper 1OsHimlxsGE1D3M5tNXTAbnOuq9UAmN2k\n",
      "Applying {0} to {1} wrapper 1OsHimlxsGE1D3M5tNXTAbnOuq9UAmN2k\n",
      "Applying {0} to {1} wrapper 1OsHimlxsGE1D3M5tNXTAbnOuq9UAmN2k\n",
      "Applying {0} to {1} wrapper 1OsHimlxsGE1D3M5tNXTAbnOuq9UAmN2k\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"list\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-70e518ef81bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_links\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-64-3d997f625abc>\u001b[0m in \u001b[0;36mapply\u001b[0;34m(genomes, transforms, log)\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Applying {0} to {1}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenome\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenome\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# transform should output some stat for us to log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenome\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenome\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"list\") to str"
     ]
    }
   ],
   "source": [
    "apply(decompress(gen_files(gen_links())), compress_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = io.BytesIO(b'232342545')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'232342545'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.read(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    for i in range(10):\n",
    "        yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in f(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genomecompression",
   "language": "python",
   "name": "genomecompression"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
